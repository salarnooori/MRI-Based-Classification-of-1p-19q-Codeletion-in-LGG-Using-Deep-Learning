{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from monai.networks.nets import EfficientNetBN, Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3\n",
    "\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = './TCIA_LGG_cases_159.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "file_label_map = {}\n",
    "for index, row in df.iterrows():\n",
    "    filename = row['Filename']\n",
    "    label = row['1p/19q']\n",
    "    if isinstance(filename, str) and isinstance(label, str):\n",
    "      file_label_map[filename] = label\n",
    "\n",
    "file_paths = []\n",
    "base_names = set()\n",
    "# labels = []\n",
    "\n",
    "nifti_dir = './grouped_data'\n",
    "for filename in os.listdir(nifti_dir):\n",
    "    if filename.endswith(\".nii.gz\") and 'tumor' not in filename.lower():\n",
    "        base_name = filename.split(\"_\")[0]\n",
    "        if base_name in file_label_map:\n",
    "            # label = file_label_map[base_name]\n",
    "            file_paths.append(os.path.join(nifti_dir, filename))\n",
    "            base_names.add(base_name)\n",
    "            # labels.append(label)\n",
    "        else:\n",
    "            print(f\"File: {filename}, Label: Not found in Excel file - skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for base in base_names:\n",
    "    sample = {'base_name': base,}\n",
    "    # find the files in file_paths which have the base in their name and add them as a list to sample['files']\n",
    "    sample['files'] = [file for file in file_paths if base in file]\n",
    "    # find the label for the base, convert it to a 0 if it's \"n/n\" and a 1 if it's \"d/d\" and add it to sample['label']\n",
    "    sample['label'] = 0 if file_label_map[base] == 'n/n' else 1\n",
    "    labels.append(sample['label'])\n",
    "    data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(subject_name, nifti_dir='./grouped_data'):\n",
    "    for filename in os.listdir(nifti_dir):\n",
    "        if filename.endswith(\".nii.gz\") and subject_name in filename and 'tumor' not in filename.lower():\n",
    "            nifti_file = os.path.join(nifti_dir, filename)\n",
    "            break\n",
    "    try:\n",
    "        img = nib.load(nifti_file)\n",
    "        img_data = img.get_fdata()\n",
    "        print(img_data.shape)\n",
    "        num_slices = img_data.shape[2]\n",
    "\n",
    "        fig, axes = plt.subplots(int(num_slices**0.5), int(num_slices**0.5), figsize=(15, 15))\n",
    "        fig.suptitle(f\"Slices of Subject: {subject_name}\")\n",
    "\n",
    "        for i in range(num_slices):\n",
    "            row = i // int(num_slices**0.5)\n",
    "            col = i % int(num_slices**0.5)\n",
    "\n",
    "            axes[row, col].imshow(img_data[:, :, i], cmap='gray')\n",
    "            axes[row, col].set_title(f\"Slice {i + 1}\")\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        for i in range(num_slices, int(num_slices**0.5) * int(num_slices**0.5)):\n",
    "            row = i // int(num_slices**0.5)\n",
    "            col = i % int(num_slices**0.5)\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {nifti_file}: {e}\")\n",
    "        return None\n",
    "    \n",
    "show_sample('LGG-637')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for handling NIfTI images and their corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Parameters:\n",
    "            - data (list): List of dictionaries containing the file paths and labels for each sample with the following structur:\n",
    "            data = {\n",
    "                'base_name': str,\n",
    "                'files': list[str],\n",
    "                'label': int        \n",
    "            }.\n",
    "            - transform (callable, optional): Optional transform to be applied on a sample.\n",
    "\n",
    "        This function should initialize the NiftiDataset with the provided data and transform.\n",
    "        First, it should load the two nifti files in data[files] and concatenate them into a single 4D torch tensor.\n",
    "        Then, it should apply the transform if it is not None.\n",
    "        Finally, it should create a list of tuples of the form (torch.Tensor, torch.int) where the first element is the 4D torch tensor and the second element is the corresponding label.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for sample in self.data:\n",
    "            img_data = []\n",
    "            for file in sample['files']:\n",
    "                img = nib.load(file)\n",
    "                img_data.append(torch.tensor(img.get_fdata(), dtype=torch.float))\n",
    "            img_data = torch.cat(img_data, dim=2)\n",
    "            img_data = img_data.permute(2, 0, 1)\n",
    "            label = torch.tensor(sample['label'])\n",
    "            self.samples.append((img_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the item at the given index.\n",
    "\n",
    "        Parameters:\n",
    "            - idx (int): Index of the item.\n",
    "\n",
    "        Returns:\n",
    "            - tuple: Tuple containing the 4D torch tensor and the label at the given index.\n",
    "        \"\"\"\n",
    "        sample = self.samples[idx]\n",
    "        if self.transform:\n",
    "            sample = (self.transform(sample[0]), sample[1])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets (80% train, 20% val) such that the train_data is less imbalanced\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, stratify=labels)\n",
    "\n",
    "# balance the train_data classes by duplicating the samples of the minority class\n",
    "minority_samples = [sample for sample in train_data if sample['label'] == 0]\n",
    "train_data.extend(minority_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [73.42668914794922]\n",
    "std = [288.2677307128906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=.5),\n",
    "    transforms.RandomVerticalFlip(p=.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(.1, .1)),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5),\n",
    "])\n",
    "\n",
    "# valid_transform = None\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = NiftiDataset(train_data, transform=train_transform)\n",
    "test_dataset = NiftiDataset(val_data, transform=valid_transform)\n",
    "\n",
    "# create an augmented 5-fold dataset from train_data\n",
    "train_dataset = NiftiDataset(train_data * 3, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check data shapes (optional)\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Image batch shape: {images.shape}, Label batch shape: {labels.shape}\")\n",
    "    break  # Just checking one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Dice Loss for binary classification\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        intersection = torch.sum(y_true * y_pred)\n",
    "        union = torch.sum(y_true) + torch.sum(y_pred)\n",
    "        dice = 2 * intersection / (union + 1e-6)\n",
    "        return 1 - dice\n",
    "    \n",
    "# Implementation of Focal Loss for binary classification\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        bce = nn.BCELoss(reduction='none')(y_pred, y_true)\n",
    "        alpha = self.alpha * y_true + (1 - self.alpha) * (1 - y_true)\n",
    "        loss = alpha * (1 - y_pred) ** self.gamma * bce\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proper combination of Dice and BCEwithLogits loss for binary classification\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # 2x weight for Dice loss\n",
    "        return self.dice_loss(y_pred, y_true) + self.bce_loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def train_model(model, train_loader, test_loader, num_epochs=100, lr=1e-4, device=None):\n",
    "    \"\"\"\n",
    "    Fine-tunes the EfficientNet-B1 model on the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The modified EfficientNet-B1 model.\n",
    "        train_loader (DataLoader): DataLoader for training set.\n",
    "        test_loader (DataLoader): DataLoader for validation/test set.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        lr (float): Learning rate.\n",
    "        device (torch.device): Device (CPU/GPU) to train on.\n",
    "\n",
    "    Returns:\n",
    "        model: The trained model.\n",
    "    \"\"\"\n",
    "    # Ensure device is set\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = CombinedLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    # LR Scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "\n",
    "    # Track best model (based on validation accuracy)\n",
    "    best_acc = 0.0\n",
    "    best_loss = 10000000000.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # # --- TRAINING PHASE ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Ensure correct shape\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = (outputs >= 0).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # --- VALIDATION PHASE ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            for images, labels in tqdm(test_loader, desc=\"Validation\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                preds = (outputs >= 0).float()\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(preds.squeeze().tolist())\n",
    "                all_labels.extend(labels.squeeze().tolist())\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "\n",
    "        # Print log\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4%}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4%}\")\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_loss = val_loss\n",
    "                # Save the trained model\n",
    "                output_dir = \"./output_models/\"\n",
    "                model_path = os.path.join(output_dir, \"efficientnet_b1_trained_2.pth\")\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"Model saved to {model_path}\")\n",
    "        elif val_acc == best_acc and val_loss <= best_loss:\n",
    "                best_loss = val_loss\n",
    "                # Save the trained model\n",
    "                output_dir = \"./output_models/\"\n",
    "                model_path = os.path.join(output_dir, \"efficientnet_b1_trained_2.pth\")\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    print(f\"\\nBest Validation Accuracy: {best_acc:.4%}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = EfficientNetBN(model_name=\"efficientnet-b0\", spatial_dims=2, in_channels=112, num_classes=1, pretrained=True)\n",
    "# model = Densenet121(spatial_dims=2, in_channels=112, out_channels=1, pretrained=True)\n",
    "# model.load_state_dict(torch.load(\"./output_models/efficientnet_b0_trained_750.pth\"))\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Model loaded to device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, train_loader, test_loader, num_epochs=30, lr=2e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
