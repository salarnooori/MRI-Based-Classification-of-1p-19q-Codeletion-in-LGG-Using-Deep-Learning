{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install the required packages\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "\n",
    "# If requirements.txt is present, switch the commented line\n",
    "!pip3 install gdown==5.2.0 ipykernel==6.29.5 monai==1.4.0 nibabel==5.3.2 pip==25.0 PySocks==1.7.1 scikit-learn==1.6.1 seaborn==0.13.2\n",
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from monai.networks.nets import EfficientNetBN, Densenet121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1PJ7LPEWIiH9DU45lCLF93plnCIqFst8m\n",
      "To: e:\\U\\S\\01 - 4031\\IABI\\Proj\\Inference\\trained_effb0.zip\n",
      "100%|██████████| 15.2M/15.2M [00:02<00:00, 5.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./trained_effb0.zip\n",
      "  inflating: ./trained_effb0.pth     \n"
     ]
    }
   ],
   "source": [
    "state_dict_url = \"https://drive.google.com/uc?export=download&id=1PJ7LPEWIiH9DU45lCLF93plnCIqFst8m\"\n",
    "\n",
    "# download using gdown\n",
    "gdown.download(state_dict_url, \"./trained_effb0.zip\", quiet=False)\n",
    "\n",
    "!unzip -o \"./trained_effb0.zip\" -d \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data and label csv directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir = './lgg_labels.csv'\n",
    "input_dir = \"./test_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model, and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = [73.42668914794922]\n",
    "std = [288.2677307128906]\n",
    "\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "model = EfficientNetBN(model_name=\"efficientnet-b0\",\n",
    "                       spatial_dims=2, in_channels=112, num_classes=1)\n",
    "model.load_state_dict(torch.load(\"./trained_effb0.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# read labels from label_dir\n",
    "labels = []\n",
    "with open(label_dir, 'r') as f:\n",
    "    for line in f:\n",
    "        labels.append(line.strip())\n",
    "\n",
    "# process the labels\n",
    "labels.pop(0)\n",
    "labels = [i.split(',')[0] for i in labels]\n",
    "\n",
    "# convert elements of labels as follows: \"Co-deletion\" -> 0, \"d/d\" -> 0, \"intact\" -> 1, \"n/n\" -> 1\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == \"Co-deletion\" or labels[i] == \"d/d\":\n",
    "        labels[i] = 0\n",
    "    else:\n",
    "        labels[i] = 1\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "##### (Assuming the data has been properly preprocessed by the given standards of the project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_slices(img):\n",
    "    \"\"\"Removes black slices (slices with all pixel values equal to 0) from a preloaded NIfTI image.\n",
    "\n",
    "    Args:\n",
    "        img: Preloaded NIfTI image.\n",
    "\n",
    "    Returns:\n",
    "        The modified NIfTI image (or None if an error occurs).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_data = img.get_fdata()\n",
    "\n",
    "        # Calculate sum of all pixels in each slice\n",
    "        slice_sums = np.sum(img_data, axis=(0, 1))\n",
    "\n",
    "        # Identify slices to keep (non-zero sum)\n",
    "        slices_to_keep = np.where(slice_sums != 0)[0]\n",
    "\n",
    "        # Extract those slices\n",
    "        new_data = img_data[:, :, slices_to_keep]\n",
    "\n",
    "        # Create a new NIfTI image with updated data\n",
    "        new_affine = img.affine.copy()\n",
    "        # Modify affine to reflect changes in z-axis dimension\n",
    "        new_affine[2, 3] = new_affine[2, 3] + \\\n",
    "            slices_to_keep[0]  # Or appropriate adjustment\n",
    "\n",
    "        new_img = nib.Nifti1Image(new_data, new_affine, header=img.header)\n",
    "        # Update header's dimensions\n",
    "        new_img.header.set_data_shape(new_data.shape)\n",
    "\n",
    "        return new_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "##### (Assuming the data has been properly preprocessed by the given standards of the project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_slices(data, target_slices):\n",
    "    \"\"\"\n",
    "    If the image has less than half of the target slices, duplicate slices to improve interpolation quality.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): The 3D MRI data.\n",
    "        target_slices (int): The desired number of slices.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: The expanded data before interpolation.\n",
    "    \"\"\"\n",
    "    current_slices = data.shape[2]\n",
    "\n",
    "    if current_slices < target_slices / 2:\n",
    "        # Determine duplication factor\n",
    "        factor = int(target_slices // current_slices)\n",
    "        expanded_data = np.repeat(data, factor, axis=2)\n",
    "\n",
    "        # If still below the target, add one more duplication pass\n",
    "        while expanded_data.shape[2] < target_slices / 2:\n",
    "            expanded_data = np.repeat(expanded_data, 2, axis=2)\n",
    "\n",
    "        return expanded_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nifti_image(nii, target_slices=64, order=3):\n",
    "    \"\"\"\n",
    "    Interpolates a NIfTI image to have a uniform number of slices, handling very thin images with duplication first.\n",
    "\n",
    "    Parameters:\n",
    "        nii (nib.Nifti1Image): Preloaded NIfTI image.\n",
    "        target_slices (int): Desired number of slices.\n",
    "        order (int): Interpolation order (default is 3 for cubic).\n",
    "\n",
    "    Returns:\n",
    "        nib.Nifti1Image: Interpolated NIfTI image.\n",
    "    \"\"\"\n",
    "    data = nii.get_fdata()\n",
    "\n",
    "    # Handle very thin images by duplicating slices before interpolation\n",
    "    data = duplicate_slices(data, target_slices)\n",
    "\n",
    "    # Compute scale factors for interpolation\n",
    "    scale_factors = (1, 1, target_slices / data.shape[2])\n",
    "\n",
    "    # Apply interpolation\n",
    "    resampled_data = zoom(data, scale_factors, order=order)\n",
    "\n",
    "    # Create the new NIfTI image\n",
    "    new_nii = nib.Nifti1Image(\n",
    "        resampled_data, affine=nii.affine, header=nii.header)\n",
    "\n",
    "    return new_nii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "In the following plot, '+' means intact (n/n), and '-' means codeleted (d/d).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a list of all the folders directly inside the input directory\n",
    "subdirs = [os.path.join(input_dir, x) for x in os.listdir(\n",
    "    input_dir) if os.path.isdir(os.path.join(input_dir, x))]\n",
    "\n",
    "data = []\n",
    "\n",
    "# each directory in subdirs contains a two nii files, one for T1, and one for T2 image. Load them\n",
    "for idx, subdir in enumerate(subdirs):\n",
    "    sample = {'id': idx,\n",
    "              'filepath': subdir,\n",
    "              'label': labels[idx]}\n",
    "    # get the list of files in the subdirectory\n",
    "    files = os.listdir(subdir)\n",
    "    t1_path = [x for x in files if 't1c' in x][0]\n",
    "    t2_path = [x for x in files if 't2w' in x][0]\n",
    "\n",
    "    t1_img = nib.load(subdir + \"/\" + t1_path)\n",
    "    t2_img = nib.load(subdir + \"/\" + t2_path)\n",
    "\n",
    "    # remove black slices\n",
    "    t1_img = remove_black_slices(t1_img)\n",
    "    t2_img = remove_black_slices(t2_img)\n",
    "\n",
    "    # interpolate the images to have 56 slices\n",
    "    t1_img = interpolate_nifti_image(t1_img, target_slices=56)\n",
    "    t2_img = interpolate_nifti_image(t2_img, target_slices=56)\n",
    "\n",
    "    # get the image data\n",
    "    t1_img = t1_img.get_fdata()\n",
    "    t2_img = t2_img.get_fdata()\n",
    "\n",
    "    # convert the images to float tensor\n",
    "    t1_img = torch.tensor(t1_img).float()\n",
    "    t2_img = torch.tensor(t2_img).float()\n",
    "\n",
    "    # normalize the images using torchvision transforms\n",
    "    t1_img = inference_transform(t1_img)\n",
    "    t2_img = inference_transform(t2_img)\n",
    "\n",
    "    # concat the images\n",
    "    img_data = [t1_img, t2_img]\n",
    "    img_data = torch.cat(img_data, dim=2)\n",
    "    img_data = img_data.permute(2, 0, 1)\n",
    "\n",
    "    output = model(img_data.unsqueeze(0))\n",
    "    pred = (output >= 0).float()\n",
    "    sample['prediction'] = pred.item()\n",
    "\n",
    "    data.append(sample)\n",
    "\n",
    "# calculate confusion matrix\n",
    "y_true = [x['label'] for x in data]\n",
    "y_pred = [x['prediction'] for x in data]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# calculate accuracy, precision, recall, and F1-score\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# print the metrics nicely\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\", end='\\n\\n')\n",
    "\n",
    "\n",
    "# plot the confusion matrix\n",
    "# modify the confusion matrix to include labels\n",
    "print(\"In the following plot, '+' means intact (n/n), and '-' means codeleted (d/d).\")\n",
    "cm_with_labels = np.array([[f\"TN = {tn}\", f\"FP = {fp}\"],\n",
    "                           [f\"FN = {fn}\", f\"TP = {tp}\"]])\n",
    "\n",
    "sns.heatmap(cm, annot=cm_with_labels, cmap='RdYlGn',\n",
    "            fmt='', annot_kws={\"size\": 7})\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks([0.5, 1.5], ['-', '+'])\n",
    "plt.yticks([0.5, 1.5], ['-', '+'])\n",
    "plt.gcf().set_size_inches(2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
