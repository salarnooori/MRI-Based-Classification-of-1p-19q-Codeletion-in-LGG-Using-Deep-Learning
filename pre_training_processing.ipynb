{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# file_id = \"1MHw4Ufxck5NuHlSMi1PUfiXQhy0vcKOE\"\n",
    "# url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "# gdown.download(url, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_slices(nifti_file):\n",
    "    \"\"\"Removes black slices (slices with all pixel values equal to 0) from a NIfTI file.\n",
    "\n",
    "    Args:\n",
    "        nifti_file: Path to the NIfTI file.\n",
    "\n",
    "    Returns:\n",
    "        The path to the modified NIfTI file (or None if an error occurs).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = nib.load(nifti_file)\n",
    "        img_data = img.get_fdata()\n",
    "\n",
    "        #Calculate sum of all pixels in each slice\n",
    "        slice_sums = np.sum(img_data, axis=(0, 1))\n",
    "\n",
    "        #Identify slices to keep (non-zero sum)\n",
    "        slices_to_keep = np.where(slice_sums != 0)[0]\n",
    "\n",
    "        #Extract those slices\n",
    "        new_data = img_data[:, :, slices_to_keep]\n",
    "\n",
    "        #Create a new NIfTI image with updated data\n",
    "        new_affine = img.affine.copy()\n",
    "        #Modify affine to reflect changes in z-axis dimension\n",
    "        new_affine[2,3] = new_affine[2,3] + slices_to_keep[0] # Or appropriate adjustment\n",
    "\n",
    "\n",
    "        new_img = nib.Nifti1Image(new_data, new_affine, header=img.header)\n",
    "        #Update header's dimensions\n",
    "        new_img.header.set_data_shape(new_data.shape)\n",
    "\n",
    "        #Save new image with filename modified to show removal of slices\n",
    "        new_nifti_file = nifti_file.replace('.nii.gz', '_no_black_slices.nii.gz').replace('skullstripped_nifti','final_data')\n",
    "        nib.save(new_img, new_nifti_file)\n",
    "\n",
    "        return new_nifti_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {nifti_file}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skullstripped_nifti_dir = './skullstripped_nifti'\n",
    "\n",
    "for file_list, label_list in [ (train_files, train_labels), (test_files, test_labels)]:\n",
    "    for i, nifti_file in enumerate(file_list):\n",
    "      if os.path.exists(nifti_file):\n",
    "          new_nifti = remove_black_slices(nifti_file)\n",
    "          if new_nifti:\n",
    "\n",
    "              file_list[i] = new_nifti\n",
    "      else:\n",
    "        print(f\"File not found: {nifti_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_T1_T2(file_pair):\n",
    "    \"\"\"\n",
    "    Given a list of 2 file names, returns a tuple (T1, T2, ambiguous)\n",
    "    where T1 and T2 are the chosen file names (in that order) and\n",
    "    ambiguous is a boolean that is True if the decision was ambiguous.\n",
    "    \"\"\"\n",
    "    # Keywords that suggest T1 and T2 characteristics.\n",
    "    t1_keywords = ['t1', 'spgr', 'flash', 'bravo', 'gre', 't1post', 't1flash3d']\n",
    "    t2_keywords = ['t2', 'fse', 't2fse', 'ax_t2', 'tset2rst', 't2_rst']\n",
    "\n",
    "    def is_t1(fname):\n",
    "        lower = fname.lower()\n",
    "        return any(kw in lower for kw in t1_keywords)\n",
    "    \n",
    "    def is_t2(fname):\n",
    "        lower = fname.lower()\n",
    "        return any(kw in lower for kw in t2_keywords)\n",
    "\n",
    "    if len(file_pair) != 2:\n",
    "        raise ValueError(\"The function expects a list of exactly two file names.\")\n",
    "\n",
    "    f1, f2 = file_pair[0], file_pair[1]\n",
    "    f1_t1 = is_t1(f1)\n",
    "    f1_t2 = is_t2(f1)\n",
    "    f2_t1 = is_t1(f2)\n",
    "    f2_t2 = is_t2(f2)\n",
    "\n",
    "    # Case 1: One file clearly is T1 and the other clearly is T2.\n",
    "    if f1_t1 and f2_t2:\n",
    "        return (f1, f2, False)\n",
    "    if f1_t2 and f2_t1:\n",
    "        return (f2, f1, False)\n",
    "    \n",
    "    # Case 2: Only one file shows a clear T1 signature.\n",
    "    if f1_t1 and not f2_t1:\n",
    "        return (f1, f2, False)  # f1 is T1, assume f2 must be T2\n",
    "    if f2_t1 and not f1_t1:\n",
    "        return (f2, f1, False)  # f2 is T1, so f1 is T2\n",
    "    \n",
    "    # Case 3: Only one file shows a clear T2 signature.\n",
    "    if f1_t2 and not f2_t2:\n",
    "        return (f2, f1, False)  # f1 is T2, so f2 becomes T1\n",
    "    if f2_t2 and not f1_t2:\n",
    "        return (f1, f2, False)  # f2 is T2, so f1 becomes T1\n",
    "    \n",
    "    # Case 4: Ambiguous situation (both files either match both or none).\n",
    "    # In that case, we default to assuming the first is T1 and the second is T2,\n",
    "    # and set the ambiguous flag to True.\n",
    "    return (f1, f2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_subject(file_paths):\n",
    "    \"\"\"\n",
    "    Groups file paths by subject using the LGG_id (e.g., 'LGG-104') found in the filename.\n",
    "    Returns a list of tuples, where each tuple contains all files for one subject.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to group file paths by subject id.\n",
    "    groups = defaultdict(list)\n",
    "    # Regular expression pattern to capture the subject id (e.g., \"LGG-104\")\n",
    "    subject_pattern = re.compile(r'LGG-\\d+')\n",
    "    \n",
    "    for path in file_paths:\n",
    "        match = subject_pattern.search(path)\n",
    "        if match:\n",
    "            subject_id = match.group()\n",
    "            groups[subject_id].append(path)\n",
    "        else:\n",
    "            print(f\"Warning: Subject ID not found in {path}\")\n",
    "    \n",
    "    # Convert each group (list) into a tuple, and return a list of tuples.\n",
    "    return [tuple(paths) for paths in groups.values()]\n",
    "\n",
    "subject_files = group_by_subject(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_images = []\n",
    "T2_images = []\n",
    "ambiguous = []\n",
    "\n",
    "for subject in subject_files:\n",
    "    T1, T2, amb = decide_T1_T2(subject)\n",
    "    if not amb:\n",
    "        T1_images.append(T1)\n",
    "        T2_images.append(T2)\n",
    "    else:\n",
    "        ambiguous.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(T1_images), len(T2_images), len(ambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(file_paths, tag):\n",
    "    \"\"\"\n",
    "    Copy files in the given list to the grouped_data directory so that the names follow the following pattern: \"LGG_id_tag.nii.gz\"\n",
    "    \"\"\"\n",
    "    for file in file_paths:\n",
    "        # Extract the subject ID from the filename.\n",
    "        subject_id = re.search(r'LGG-\\d+', file).group()\n",
    "        # Construct the new filename.\n",
    "        new_name = f\"./grouped_data/{subject_id}_{tag}.nii.gz\"\n",
    "        # Copy the files using shutil\n",
    "        shutil.copy(file, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_files(T1_images, \"T1\")\n",
    "rename_files(T2_images, \"T2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_slices(subject_name, nifti_dir='./final_data'):\n",
    "    for filename in os.listdir(nifti_dir):\n",
    "        if filename.endswith(\".nii.gz\") and subject_name in filename and 'tumor' not in filename.lower():\n",
    "            nifti_file = os.path.join(nifti_dir, filename)\n",
    "            break\n",
    "    try:\n",
    "        img = nib.load(nifti_file)\n",
    "        img_data = img.get_fdata()\n",
    "        print(img_data.shape)\n",
    "        num_slices = img_data.shape[2]\n",
    "\n",
    "        fig, axes = plt.subplots(int(num_slices**0.5), int(num_slices**0.5), figsize=(15, 15))\n",
    "        fig.suptitle(f\"Slices of Subject: {subject_name}\")\n",
    "\n",
    "        for i in range(num_slices):\n",
    "            row = i // int(num_slices**0.5)\n",
    "            col = i % int(num_slices**0.5)\n",
    "\n",
    "            axes[row, col].imshow(img_data[:, :, i], cmap='gray')\n",
    "            axes[row, col].set_title(f\"Slice {i + 1}\")\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        for i in range(num_slices, int(num_slices**0.5) * int(num_slices**0.5)):\n",
    "            row = i // int(num_slices**0.5)\n",
    "            col = i % int(num_slices**0.5)\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {nifti_file}: {e}\")\n",
    "        return None\n",
    "    \n",
    "show_all_slices('LGG-104_4.000000-Gad_Ax_T2_Straight-38151')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = './TCIA_LGG_cases_159.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "file_label_map = {}\n",
    "for index, row in df.iterrows():\n",
    "    filename = row['Filename']\n",
    "    label = row['1p/19q']\n",
    "    if isinstance(filename, str) and isinstance(label, str):\n",
    "      file_label_map[filename] = label\n",
    "\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "nifti_dir = './final_data'\n",
    "for filename in os.listdir(nifti_dir):\n",
    "    if filename.endswith(\".nii.gz\") and 'tumor' not in filename.lower():\n",
    "        base_name = filename.split(\"_\")[2].split(\".\")[0]\n",
    "        if base_name in file_label_map:\n",
    "            label = file_label_map[base_name]\n",
    "            file_paths.append(os.path.join(nifti_dir, filename))\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"File: {filename}, Label: Not found in Excel file - skipping\")\n",
    "\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(file_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train data examples:\")\n",
    "for i in range(min(5, len(train_files))):\n",
    "    print(f\"File: {train_files[i]}, Label: {train_labels[i]}\")\n",
    "\n",
    "print(\"\\nTest data examples:\")\n",
    "for i in range(min(5, len(test_files))):\n",
    "    print(f\"File: {test_files[i]}, Label: {test_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_boolean(input_list):\n",
    "    return [0 if element == 'n/n' else 1 for element in input_list]\n",
    "\n",
    "train_labels = convert_to_boolean(train_labels)\n",
    "test_labels = convert_to_boolean(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def analyze_nifti_slices(file_paths, bin_size=10):\n",
    "    \"\"\"\n",
    "    Analyzes the number of slices in a list of NIfTI files and bins the slice counts into partitions of size `bin_size`.\n",
    "\n",
    "    Parameters:\n",
    "        file_paths (list): List of file paths to NIfTI images.\n",
    "        bin_size (int): The size of each bin (default: 10).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with:\n",
    "            - \"lowest\": The smallest number of slices.\n",
    "            - \"highest\": The largest number of slices.\n",
    "            - \"median\": The median number of slices.\n",
    "            - \"average\": The average number of slices.\n",
    "            - \"variance\": The variance of slice counts.\n",
    "            - \"binned_counts\": A dictionary where keys are bin ranges and values are the count of images in that range.\n",
    "    \"\"\"\n",
    "    slice_counts = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        nii = nib.load(file_path)\n",
    "        slices = nii.shape[2]  # Extract the number of slices (Z-dimension)\n",
    "        slice_counts.append(slices)\n",
    "\n",
    "    slice_counts = np.array(slice_counts)\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        \"lowest\": int(np.min(slice_counts)),\n",
    "        \"highest\": int(np.max(slice_counts)),\n",
    "        \"median\": int(np.median(slice_counts)),\n",
    "        \"average\": float(np.mean(slice_counts)),\n",
    "        \"variance\": float(np.var(slice_counts)),\n",
    "    }\n",
    "    \n",
    "    bins = defaultdict(int)\n",
    "    \n",
    "    for count in slice_counts:\n",
    "        bin_start = (count // bin_size) * bin_size\n",
    "        bin_end = bin_start + bin_size - 1\n",
    "        bin_range = f\"{bin_start}-{bin_end}\"\n",
    "        bins[bin_range] += 1\n",
    "\n",
    "    stats[\"binned_counts\"] = dict(sorted(bins.items(), key=lambda x: int(x[0].split('-')[0])))\n",
    "\n",
    "    return stats\n",
    "\n",
    "analyze_nifti_slices(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_slices(data, target_slices):\n",
    "    \"\"\"\n",
    "    If the image has less than half of the target slices, duplicate slices to improve interpolation quality.\n",
    "    \n",
    "    Parameters:\n",
    "        data (numpy array): The 3D MRI data.\n",
    "        target_slices (int): The desired number of slices.\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: The expanded data before interpolation.\n",
    "    \"\"\"\n",
    "    current_slices = data.shape[2]\n",
    "\n",
    "    if current_slices < target_slices / 2:\n",
    "        # Determine duplication factor\n",
    "        factor = int(target_slices // current_slices)\n",
    "        expanded_data = np.repeat(data, factor, axis=2)\n",
    "\n",
    "        # If still below the target, add one more duplication pass\n",
    "        while expanded_data.shape[2] < target_slices / 2:\n",
    "            expanded_data = np.repeat(expanded_data, 2, axis=2)\n",
    "\n",
    "        print(f\"Duplicated slices from {current_slices} to {expanded_data.shape[2]} before interpolation.\")\n",
    "        return expanded_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nifti_images(file_paths, output_dir, target_slices=64, order=3):\n",
    "    \"\"\"\n",
    "    Interpolates NIfTI images to have a uniform number of slices, handling very thin images with duplication first.\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths (list): List of NIfTI file paths.\n",
    "        output_dir (str): Directory to save processed images.\n",
    "        target_slices (int): Desired number of slices.\n",
    "        order (int): Interpolation order (default is 3 for cubic).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        nii = nib.load(file_path)\n",
    "        data = nii.get_fdata()\n",
    "        original_slices = data.shape[2]\n",
    "\n",
    "        # Handle very thin images by duplicating slices before interpolation\n",
    "        data = duplicate_slices(data, target_slices)\n",
    "\n",
    "        # Compute scale factors for interpolation\n",
    "        scale_factors = (1, 1, target_slices / data.shape[2])\n",
    "\n",
    "        # Apply interpolation\n",
    "        resampled_data = zoom(data, scale_factors, order=order)\n",
    "\n",
    "        # Save the new NIfTI file\n",
    "        new_nii = nib.Nifti1Image(resampled_data, affine=nii.affine, header=nii.header)\n",
    "        output_path = os.path.join(output_dir, os.path.basename(file_path))\n",
    "        nib.save(new_nii, output_path)\n",
    "\n",
    "        print(f\"Processed: {file_path} -> {output_path} (Initial slices: {original_slices}, Target slices: {target_slices})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_nifti_images(test_files, './interpolated_data/', target_slices=56, order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_nifti_images(train_files, './interpolated_data/', target_slices=56, order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = './TCIA_LGG_cases_159.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "file_label_map = {}\n",
    "for index, row in df.iterrows():\n",
    "    filename = row['Filename']\n",
    "    label = row['1p/19q']\n",
    "    if isinstance(filename, str) and isinstance(label, str):\n",
    "      file_label_map[filename] = label\n",
    "\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "nifti_dir = './interpolated_data'\n",
    "for filename in os.listdir(nifti_dir):\n",
    "    if filename.endswith(\".nii.gz\") and 'tumor' not in filename.lower():\n",
    "        base_name = filename.split(\"_\")[2].split(\".\")[0]\n",
    "        if base_name in file_label_map:\n",
    "            label = file_label_map[base_name]\n",
    "            file_paths.append(os.path.join(nifti_dir, filename))\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"File: {filename}, Label: Not found in Excel file - skipping\")\n",
    "\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(file_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train data examples:\")\n",
    "for i in range(min(5, len(train_files))):\n",
    "    print(f\"File: {train_files[i]}, Label: {train_labels[i]}\")\n",
    "\n",
    "print(\"\\nTest data examples:\")\n",
    "for i in range(min(5, len(test_files))):\n",
    "    print(f\"File: {test_files[i]}, Label: {test_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_boolean(input_list):\n",
    "    return [0 if element == 'n/n' else 1 for element in input_list]\n",
    "\n",
    "train_labels = convert_to_boolean(train_labels)\n",
    "test_labels = convert_to_boolean(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_slices(subject_name, nifti_dir='./interpolated_data'):\n",
    "    for filename in os.listdir(nifti_dir):\n",
    "        if filename.endswith(\".nii.gz\") and subject_name in filename and 'tumor' not in filename.lower():\n",
    "            nifti_file = os.path.join(nifti_dir, filename)\n",
    "            break\n",
    "    try:\n",
    "        img = nib.load(nifti_file)\n",
    "        img_data = img.get_fdata()\n",
    "        print(img_data.shape)\n",
    "        num_slices = img_data.shape[2]\n",
    "\n",
    "        fig, axes = plt.subplots(int(num_slices**0.5), int(num_slices**0.5), figsize=(15, 15))\n",
    "        fig.suptitle(f\"Slices of Subject: {subject_name}\")\n",
    "\n",
    "        for i in range(num_slices):\n",
    "            row = i // int(num_slices**0.5)\n",
    "            col = i % int(num_slices**0.5)\n",
    "\n",
    "            axes[row, col].imshow(img_data[:, :, i], cmap='gray')\n",
    "            axes[row, col].set_title(f\"Slice {i + 1}\")\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        for i in range(num_slices, int(num_slices**0.5) * int(num_slices**0.5)):\n",
    "            row = i // int(num_slices**0.5)\n",
    "            col = i % int(num_slices**0.5)\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {nifti_file}: {e}\")\n",
    "        return None\n",
    "    \n",
    "show_all_slices('LGG-558_3.000000-axial_FSE-03138_no_black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom transform to add Gaussian noise to an image.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0.0, std=0.05):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor + torch.randn_like(tensor) * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for handling NIfTI images and their corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_paths, labels, channel_mode=\"single\", transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Parameters:\n",
    "            file_paths (list): List of file paths to NIfTI images.\n",
    "            labels (list): List of labels corresponding to each file.\n",
    "            channel_mode (str): \"single\" for (1, H, W, D) or \"multi\" for (D, H, W).\n",
    "            transform (callable, optional): Transformations to apply to the data.\n",
    "        \"\"\"\n",
    "        assert channel_mode in [\"single\", \"multi\"], \"channel_mode must be 'single' or 'multi'\"\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.channel_mode = channel_mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def load_nifti(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads a NIfTI file and interpolates it to the target number of slices.\n",
    "        \"\"\"\n",
    "        nii = nib.load(file_path)\n",
    "        data = nii.get_fdata()\n",
    "\n",
    "        # Normalize the data (min-max scaling)\n",
    "        data = (data - np.min(data)) / (np.max(data) - np.min(data) + 1e-8)\n",
    "\n",
    "        # Convert to PyTorch tensor\n",
    "        tensor_data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "        if self.channel_mode == \"single\":\n",
    "            # Option 1: Keep a single channel (for 3D CNNs)\n",
    "            tensor_data = tensor_data.unsqueeze(0)  # Shape: (1, H, W, D)\n",
    "        else:\n",
    "            # Option 2: Treat slices as channels (for 2D CNNs)\n",
    "            tensor_data = tensor_data.permute(2, 0, 1)  # Shape: (D, H, W)\n",
    "\n",
    "        return tensor_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the image tensor and label for a given index.\n",
    "        \"\"\"\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load and preprocess the NIfTI image\n",
    "        image = self.load_nifti(file_path)\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of the images in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (Dataset): The dataset containing the images.\n",
    "\n",
    "    Returns:\n",
    "        mean (float): The mean of the pixel values.\n",
    "        std (float): The standard deviation of the pixel values.\n",
    "    \"\"\"\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    for image, _ in tqdm(dataset, desc=\"Calculating mean and std\"):\n",
    "        # Sum up the pixel values and the squared pixel values\n",
    "        mean += image.mean().item()\n",
    "        std += image.std().item()\n",
    "        num_samples += image.size(0)\n",
    "\n",
    "    mean /= num_samples\n",
    "    std /= num_samples\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "train_dataset = NiftiDataset(train_files, train_labels, channel_mode=\"single\")\n",
    "mean, std = calculate_mean_std(train_dataset)\n",
    "print(f\"Mean: {mean}, Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    # GaussianNoise(std=0.05),\n",
    "    transforms.Normalize(mean=[mean,], std=[std]),\n",
    "])\n",
    "\n",
    "# valid_transform = None\n",
    "valid_transform = transforms.Compose([\n",
    "    # transforms.Normalize(mean=[mean], std=[std]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NiftiDataset(train_files, train_labels, channel_mode=\"multi\", transform=train_transform)\n",
    "test_dataset = NiftiDataset(test_files, test_labels, channel_mode=\"multi\", transform=valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check data shapes (optional)\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Image batch shape: {images.shape}, Label batch shape: {labels.shape}\")\n",
    "    break  # Just checking one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNet-B1 with an additional 56 → 64 projection layer for MRI slices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=2, input_channels=56, binary=True):\n",
    "        super(CustomEfficientNet, self).__init__()\n",
    "\n",
    "        # Load pretrained EfficientNet-B1\n",
    "        self.efficientnet = models.efficientnet_b1(pretrained=True)\n",
    "\n",
    "        # Modify EfficientNet's first convolutional layer to match 64 → 32 transition\n",
    "        self.efficientnet.features[0][0] = nn.Conv2d(\n",
    "            in_channels=56,  # Match the new projection layer\n",
    "            out_channels=32,  # EfficientNet's expected out_channels\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        # Modify the classifier for binary/multi-class classification\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "\n",
    "        if binary:\n",
    "            self.efficientnet.classifier[1] = nn.Sequential(\n",
    "                nn.Dropout(0.3),  # Regularization to prevent overfitting\n",
    "                nn.Linear(num_ftrs, 1)  # Binary classification (BCEWithLogitsLoss)\n",
    "            )\n",
    "        else:\n",
    "            self.efficientnet.classifier[1] = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(num_ftrs, num_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)  # Pass through EfficientNet-B1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=80, device=None):\n",
    "    \"\"\"\n",
    "    Fine-tunes the CustomEfficientNet model on the given dataset.\n",
    "\n",
    "    For the optimizer:\n",
    "      - The first convolution (model.efficientnet.features[0][0]) uses a base lr=5e-4 \n",
    "        which is scheduled (cosine annealed) over 80 epochs from 5e-4 down to 1e-4.\n",
    "      - The rest of the parameters have a base lr=1e-4 but are effectively set to:\n",
    "            * 1e-5 for the first 20 epochs (i.e. multiplier=0.1)\n",
    "            * At epoch 20, the lr “jumps” to 1e-4, and then a cosine annealing schedule\n",
    "              (over the remaining 60 epochs) brings it down to 1e-5 by epoch 80.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The modified EfficientNet-B3 model.\n",
    "        train_loader (DataLoader): DataLoader for training set.\n",
    "        test_loader (DataLoader): DataLoader for validation/test set.\n",
    "        num_epochs (int): Number of training epochs (should be 80).\n",
    "        device (torch.device): Device (CPU/GPU) to train on.\n",
    "\n",
    "    Returns:\n",
    "        model: The trained model.\n",
    "    \"\"\"\n",
    "    # Set device if not provided\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Setup parameter groups for the optimizer:\n",
    "    #   Group 1: First conv layer (features[0][0])\n",
    "    #   Group 2: All the rest of the parameters.\n",
    "    # -------------------------------\n",
    "    first_conv_params = list(model.efficientnet.features[0][0].parameters())\n",
    "    # Compare parameters by their id to avoid tensor equality issues.\n",
    "    first_conv_ids = set(map(id, first_conv_params))\n",
    "    other_params = [p for p in model.parameters() if id(p) not in first_conv_ids]\n",
    "\n",
    "    # For Group 1 we set base lr=5e-4.\n",
    "    # For Group 2 we set base lr=1e-4 (we will apply a multiplier so that for the first 20 epochs\n",
    "    # the effective lr is 1e-4 * 0.1 = 1e-5).\n",
    "    optimizer = optim.AdamW([\n",
    "        {\"params\": first_conv_params, \"lr\": 5e-4},\n",
    "        {\"params\": other_params, \"lr\": 1e-4}\n",
    "    ], weight_decay=1e-5)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Define custom lambda functions for each parameter group.\n",
    "    #\n",
    "    # Group 1 (first conv layer):\n",
    "    #   Cosine annealing schedule over all 80 epochs from 5e-4 to 1e-4.\n",
    "    #   Effective lr = 1e-4 + 0.5*(5e-4 - 1e-4)*(1 + cos(pi * epoch / 80)).\n",
    "    #   Multiplier (relative to base lr of 5e-4) is:\n",
    "    #       multiplier = (1e-4 + 0.5*(4e-4)*(1+cos(pi*epoch/80)))/5e-4.\n",
    "    #\n",
    "    # Group 2 (all other layers):\n",
    "    #   For epochs 0–19, effective lr = 1e-4 * 0.1 = 1e-5.\n",
    "    #   For epochs 20–80, cosine annealing over 60 epochs from 1e-4 to 1e-5:\n",
    "    #       effective_lr = 1e-5 + 0.5*(1e-4-1e-5)*(1 + cos(pi * (epoch-20) / 60)).\n",
    "    #   Dividing by the base lr (1e-4) gives the multiplier.\n",
    "    # -------------------------------\n",
    "    def lambda1(epoch):\n",
    "        # For group 1: from 5e-4 (epoch 0) to 1e-4 (epoch 80)\n",
    "        return (1e-4 + 0.5*(5e-4 - 1e-4) * (1 + math.cos(math.pi * epoch / 80))) / 5e-4\n",
    "\n",
    "    def lambda2(epoch):\n",
    "        # For group 2:\n",
    "        if epoch < 20:\n",
    "            return 0.1  # Effective lr = 1e-4 * 0.1 = 1e-5.\n",
    "        else:\n",
    "            t = epoch - 20\n",
    "            return (1e-5 + 0.5 * (1e-4 - 1e-5) * (1 + math.cos(math.pi * t / 60))) / 1e-4\n",
    "\n",
    "    # Create the scheduler with a list of lambda functions (one per parameter group)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda1, lambda2])\n",
    "    \n",
    "    # Loss function (using BCEWithLogitsLoss for binary classification)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # For tracking the best model (by validation accuracy)\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Optionally, print the current effective learning rates:\n",
    "        current_lrs = scheduler.get_last_lr()\n",
    "        print(f\"Current effective LRs: Group1 (first conv): {current_lrs[0]:.2e}, Group2 (others): {current_lrs[1]:.2e}\")\n",
    "\n",
    "        # --- TRAINING PHASE ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images = images.to(device)\n",
    "            # For binary classification, ensure labels are floats and have shape [batch, 1]\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # --- VALIDATION PHASE ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc=\"Validation\", leave=False):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device).float().unsqueeze(1)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                preds = torch.sigmoid(outputs).round()\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4%}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4%}\")\n",
    "\n",
    "        # Step the scheduler (updates both parameter groups)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save the best model based on validation accuracy.\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f\"\\nBest Validation Accuracy: {best_acc:.4%}\")\n",
    "\n",
    "    # Load best model weights (if available)\n",
    "    if best_model_wts is not None:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, train_loader, test_loader, num_epochs=20, lr=1e-4, device=None):\n",
    "#     \"\"\"\n",
    "#     Fine-tunes the EfficientNet-B1 model on the given dataset.\n",
    "\n",
    "#     Parameters:\n",
    "#         model (torch.nn.Module): The modified EfficientNet-B1 model.\n",
    "#         train_loader (DataLoader): DataLoader for training set.\n",
    "#         test_loader (DataLoader): DataLoader for validation/test set.\n",
    "#         num_epochs (int): Number of training epochs.\n",
    "#         lr (float): Learning rate.\n",
    "#         device (torch.device): Device (CPU/GPU) to train on.\n",
    "\n",
    "#     Returns:\n",
    "#         model: The trained model.\n",
    "#     \"\"\"\n",
    "#     # Ensure device is set\n",
    "#     if device is None:\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     # Define loss function and optimizer\n",
    "#     criterion = nn.BCEWithLogitsLoss()  # For binary classification\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "#     # LR Scheduler\n",
    "#     scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "\n",
    "#     # Track best model (based on validation accuracy)\n",
    "#     best_acc = 0.0\n",
    "#     best_model_wts = None\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "#         # --- TRAINING PHASE ---\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "#             images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Ensure correct shape\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)  # Forward pass\n",
    "#             loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             preds = torch.sigmoid(outputs).round()  # Convert logits to 0/1 predictions\n",
    "#             correct += (preds == labels).sum().item()\n",
    "#             total += labels.size(0)\n",
    "\n",
    "#         train_loss = running_loss / total\n",
    "#         train_acc = correct / total\n",
    "\n",
    "#         # --- VALIDATION PHASE ---\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         val_correct = 0\n",
    "#         val_total = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in tqdm(test_loader, desc=\"Validation\", leave=False):\n",
    "#                 images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 val_loss += loss.item() * images.size(0)\n",
    "#                 preds = torch.sigmoid(outputs).round()\n",
    "#                 val_correct += (preds == labels).sum().item()\n",
    "#                 val_total += labels.size(0)\n",
    "\n",
    "#         val_loss /= val_total\n",
    "#         val_acc = val_correct / val_total\n",
    "\n",
    "#         # Print log\n",
    "#         print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4%}\")\n",
    "#         print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4%}\")\n",
    "\n",
    "#         # Update learning rate\n",
    "#         scheduler.step()\n",
    "\n",
    "#         # Save best model\n",
    "#         if val_acc > best_acc:\n",
    "#             best_acc = val_acc\n",
    "#             best_model_wts = model.state_dict()\n",
    "\n",
    "#     print(f\"\\nBest Validation Accuracy: {best_acc:.4%}\")\n",
    "    \n",
    "#     # Load best model weights\n",
    "#     if best_model_wts is not None:\n",
    "#         model.load_state_dict(best_model_wts)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  # Tumor vs. no tumor\n",
    "input_channels = 56  # Number of MRI slices (D)\n",
    "binary_classification = True  # Set to True for binary classification\n",
    "\n",
    "model = CustomEfficientNet(num_classes, input_channels, binary_classification)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_model(model, train_loader, test_loader, num_epochs=80)\n",
    "# Create the output directory if it doesn't exist\n",
    "output_dir = \"./output_models/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = os.path.join(output_dir, \"efficientnet_b1_trained.pth\")\n",
    "torch.save(trained_model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
